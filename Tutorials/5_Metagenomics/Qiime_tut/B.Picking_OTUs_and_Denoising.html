<!Doctype HTML>
<html lang="en">
     <head>
          <meta charset="UTF-8">
          <title>liquid layout</title>

     </head>

<body style="width: 90%">

<a href="A.Trimming_Barcodes.html">A. Trimming Barcodes</a><br>


<h2>B. Picking OTUs and Denoising</h2>
<div><b><span style="color:rgb(19,79,92)">Goals</span></b><br style="color:rgb(19,79,92)"><div style="color:rgb(19,79,92)"><ul><li style="list-style-position:outside;list-style-type:square">Denoise 454 sequences using Denoiser</li><li style="list-style-position:outside;list-style-type:square">Cluster sequences into operational taxonomic units</li><li style="list-style-position:outside;list-style-type:square">Pick a representative set of sequences</li></ul></div><h4><a name="TOC-Denoise-Seqs-with-Denoiser"></a>Denoise Seqs with Denoiser</h4>
<div><b>This Denoiser step only applies to 454 Pyrosequencing data. It can be skipped, at your own risk.</b><br>
<br>
One problem with 454 pyrosequencing is that sequencing errors can give
you effectively more OTUs than really are there. There are a number of
strategies for dealing with this problem. The default in QIIME is to use
 a built-in program called Denoiser, which compares flowgrams (the raw
sequencing data) of similar sequences to see if the differences between
them may have been due to erroneous base calls. You can see some of this
 raw sequencing <i>flowgram</i> data by opening the Fasting_Example.sff.txt file in <i>less</i>.&nbsp;
 This is a text version of the "SFF" raw data format generated by the
454 pyrosequencing platform.&nbsp; It won't be terribly meaningful to
you as it is, but it's always nice to have a feel for what all the data
files look like. The "FlowGram" entry for each read gives the integrated
 signal from each consecutive reagent, T, A, G, C, T, A, G, C, etc.
These are the data that the Denoiser will use to denoise our reads.<br>
<br>
Our command (run this) is to use the script <b><a href="http://qiime.org/scripts/denoise_wrapper.html">denoise_wrapper.py</a></b> (<i>Warning: this step could take up to an hour. Once you start it, you may want to go get coffee or do something else for a bit</i>).
<br><br><i><b>(To safe time and contiue with the tutorial, you can copy the output of this step from the folder <a href="qiime_tutorial/denoiser">denoiser</a>.)</b></i><br>
<br>
<b><font style="font-family:courier new,monospace;color:rgb(56,118,29)" size="2"><b>denoise_wrapper.py -i Fasting_Example.sff.txt -f split_library_output/seqs.fna -m Fasting_Map.txt -o denoiser/</b></font></b><br>
<br>
Some of the options:&nbsp; <br><div style="margin-left:40px">
-i [filename]&nbsp; Specifies the sff.txt file name<br>
-f [filename]&nbsp; Specifies the fasta file that was created by split_libraries.py<br>
-m [filename]&nbsp; Sample mapping file with primers and barcodes<br>
-o [name]&nbsp; Specifies a directory name for the output<br></div>
<br>
</div>
<div>
It may seem inconvenient to have to wait a few minutes for this script,
but on a full 454 Titanium plate it could take days or weeks, depending
on how many CPUs you use.&nbsp; You can specify the number of CPUs by
adding the <b>-n</b> option.&nbsp; If it's titanium data, you also have to add the<b> --titanium</b> option.<br>
<br>
This script created a new output directory called <b>denoiser</b>/ which
 contains a bunch of new files. The important ones are
denoiser_mapping.txt, centroids.fasta and singletons.fasta. The
singletons had no other sequences that matched up with them, and the
centroids are representatives of clusters that collapsed into a single
sequence following denoising. The denoiser_mapping.txt file maps which
sequences fell into which centroids.&nbsp; To make use of these data, we
 have to "inflate" the results to create a new FASTA file that is a
theoretically denoised version of the original. The script that does
this for us is called&nbsp;<b><a href="http://qiime.org/scripts/inflate_denoiser_output.html">inflate_denoiser_output.py</a></b><br>
<br>
<b style="color:rgb(56,118,29)"><span style="font-family:courier new,monospace">inflate_denoiser_output.py
 -c denoiser/centroids.fasta -s denoiser/singletons.fasta -f
split_library_output/seqs.fna -d denoiser/denoiser_mapping.txt -o
inflated_denoised_seqs.fna</span></b><br>
<br>
Some of the options:<br>
<div style="margin-left:40px">-c [file]&nbsp; The centroids.fasta file from denoise_wrapper.py<br>
-s [file]&nbsp; The singletons.fasta file from denoise_wrapper.py<br>
-f [file] The seqs.fna file from split_libraries.py<br>
-d [file]&nbsp; The denoiser_mapping.txt file from denoise_wrapper.py<br>
-o [file]&nbsp; The name of the new fasta file to be created<br>
</div>
<br>
Check the contents of the newly created output file,
inflated_denoised_seqs.fna.&nbsp; It should contain all the seqs from
split_library_output/seqs.fna, but the sequences will be slightly
different depending on to what extent they were denoised.<br><br>For more complex examples and information, see the <a href="http://qiime.org/tutorials/denoising_454_data.html">Denoising Tutorial</a> on qiime.org.&nbsp; <i>Note:
 I tested this tutorial both with and without the denoising step, and
denoising reduced the number of OTUs from 417 to 209 -- quite a big
difference!</i><br>
</div>
<div>
<div style="margin-left:40px"></div>
<h4><a name="TOC-Pick-Operational-Taxonomic-Units"></a>Pick Operational Taxonomic Units<br>
</h4>
OTUs
 (operational taxonomic units) are clusters of similar sequences. Much
of the QIIME pipeline is concerned with analyzing OTUs rather than the
full set of sequences. In this OTU-centric process, you are looking at
samples as collections of OTUs, where two different samples may contain
some of the same OTUs and some different OTUs. We'll eventually assign
each OTU some data, such as taxonomy data, data as to how abundant it
was in each sample, and data on the evolutionary history of each OTU
compared to the others. There are a number of ways to bin sequences into
 these "clusters" of OTUs, a process called OTU picking.&nbsp; (Some folks
may colloquially speak of OTUs with 97% similarity threshold as being
"species," though this is just for the sake of communication where
technical lingo would bog down the conversation). The default
OTU-picking method in QIIME is to use a program called <b>uclust</b>.<br>
<br>
The
 defaults in the QIIME script pick_otus.py for OTU-picking are to use
uclust, and to use an identity threshold of 97% (i.e., sequences that
are 97% similar should get binned into the same OTU together). You can
see how to specify different options in the <a href="http://qiime.org/scripts/pick_otus.html">help info for <b>pick_otus.py</b></a>.&nbsp; We're going to use all the defaults, so all we have to specify is the input file name with the <b>-i</b> flag:<br>
<br>
<b style="color:rgb(56,118,29);font-family:courier new,monospace"><span style="color:rgb(56,118,29);font-family:courier new,monospace">pick_otus.py -i inflated_denoised_seqs.fna</span><br style="color:rgb(56,118,29);font-family:courier new,monospace">
<br></b>Notice
 that the fasta file we used as input was the output of our previous
denoising step. (If you skipped denoising, the input for the -i option
in this step could instead be <b>split_library_output/seqs.fna</b> ) Our new command should create a new directory
automatically named "uclust_picked_otus." Look inside that directory
with <i>ls</i> and you should see three new files: a .uc file, a .log
file, and a file called inflated_denoised_seqs_otus.txt.&nbsp; Let's
look at the contents of </font></font></span></span></span></span><span style="color:rgb(56,118,29);font-family:courier new,monospace"><span><span style="background-color:rgb(0,0,0)"><span style="background-color:rgb(255,255,255)"><font color="#000000"><font face="arial,sans-serif">that file:<br>
<br>
<b style="font-family:courier new,monospace;color:rgb(56,118,29)">less uclust_picked_otus/inflated_denoised_seqs_otus.txt</b><br>
<br>
It's
 another tab-separated file. This format is called an OTU map.&nbsp; It is an
 intermediate file format, and maybe not very useful to you as raw
data.&nbsp; It lists each OTU (the first column is the ID of the OTU,
counting up from 0) followed by the IDs of all the sequences that fell
into that OTU.&nbsp; My first few lines look like this:<br>
<br>

<span style="font-family:courier new,monospace">denovo0 PC.481_294      PC.354_361      PC.607_480      PC.635_705      PC.355_1121     PC.636_148      PC.636_341      PC.607_350      PC.636_712      PC.607_1088     PC.607_1099     PC.593_1323     PC.634_21       PC.607_97       PC.634_129      PC.607_590      PC.607_886      PC.635_519      PC.636_156      PC.635_308      PC.636_333      PC.607_591      PC.635_640      PC.607_1210     PC.355_731      PC.355_774      PC.481_1169     PC.607_151      PC.635_264      PC.635_383      PC.635_476      PC.636_827      PC.607_953      PC.356_1220
<br>denovo1 PC.636_266
<br>denovo2 PC.634_174      PC.634_175      PC.634_106      PC.634_121      PC.634_208</span><br><br>

You can see that OTU denovo0 contain many sequences where OTU denovo1 contain only one sequence, while
OTU denovo2 contains five sequences. Some of the OTUs contain many sequences!
<span style="color:rgb(56,118,29);font-family:courier new,monospace"><span><span style="background-color:rgb(0,0,0)"><span style="background-color:rgb(255,255,255)"><font color="#000000"><font face="arial,sans-serif"> Okay, we can quit <i>less</i> now. </font></font></span></span></span></span><br><br>Working
 with all of your sequences is cumbersome, if you are, for example,
building an alignment, assigning taxonomy, etc.&nbsp; Since we have OTUs
 picked, what we <i>really</i> would like to work with are a collection of just one representative sequence per OTU.&nbsp; We can get this using&nbsp;<b><a href="http://qiime.org/scripts/pick_rep_set.html">pick_rep_set.py</a></b>.<br><br><b><span style="color:rgb(56,118,29);font-family:courier new,monospace">pick_rep_set.py -i uclust_picked_otus/inflated_denoised_seqs_otus.txt -f inflated_denoised_seqs.fna -o rep_set.fna</span></b>
 <br><br>Some of the options:<br><div style="margin-left:40px">-i [file]&nbsp; The OTU mapping file from pick_otus.py<br>-f [file]&nbsp; The fasta file that was used to pick OTUs<br>-o [file]&nbsp; The name of the output FASTA file to create<br></div>
 <br>How many sequences are in our resulting FASTA file? We can do <b>grep -c "&gt;" rep_set.fna</b> to see: mine has 209 sequences in it (one for each OTU). What does the file format look like?&nbsp; Check it out using <i>less</i>:<br><br><b>
 <font style="font-family:courier new,monospace" size="1">
    &gt;denovo0 PC.481_294<br>CTGGTCCGTGTCTCAGTACCAGTGTGGGGGACCTTCCTCTCAGAACCCCTACGCATCGTCG<br>GTTAGGTGGGCCGTTACCCCGCCTACTGCCTAATGCGCCGCATGCCCATCCTCCACCGGT<br>AATCCTTTCCTCCCCCAAGGATGCCCCCAAGGGATATACGCGGGATTAGCCTCCCTTTCG<br>GAAGGTTGTCCCCCTGTGGAGGGCAGGTTGCATACGTGTTACTCACCCGTGCGCCAGTCGCCGGCAG
<br>&gt;denovo1 PC.636_266<br>CTGGACCGTGTCTCAGTTCCAGTGTGGCCGATCACCCTCTCAGGTCGGCTACGTATCGTCG<bnr>CCTTGGTAAGCCGTTACCTTACCAACTAGCTAATACGGCGCGGGTCCATCTATAAGTGA<br>TAGCAAAACCATCTTTCACTTTAGAACCATGCGGTTCTAAATGTTATCCGGTATTAGCTC<br>CGGTTTCCCGAAGTTATCCCAGTCTTATAGGTAGGTTACCCACGTGTTACTCACCCGTCCGCCGCTAAG</font></b>
 <br><br>The first sequence has the ID "denovo0" -- followed by information that it came
from sequence PC.481_294, which is the representative of OTU denovo0.&nbsp;
The only important header information anymore, however, is that "denovo0" -
that is the ID of that OTU. Now we can create a table that lists how
many reads from each OTU were found in each sample (on the next page).<br><br><hr width="100%" size="2"><i>Next step</i>: <a href="C.Taxonomy_and_the_OTU_Table.html"><b>Taxonomy and the OTU Table</b></a><br>
</div></div></div></td></tr></tbody></table>
</body></html>
